{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial on Generative Inverse Heat Dissipation (ICLR 2023)\n",
    "\n",
    "Official github repository [here](https://github.com/AaltoML/generative-inverse-heat-dissipation).\n",
    "\n",
    "In this tutorial notebook, we'll investigate conditional generation properties of the Inverse Heat Dissipation Model (IHDM) for the MNIST and CIFAR10 datasets. Originally, the authors only performed unconditional generation experiments across different datasets, where the deblurring process started from a flat image\n",
    "with a certain average gray value. Here, we'll observe how a simple class-conditioning embedding can guide the UNet's output to a specific class. This extension enhances the model's intra-class generation variance as the generation landscape becomes more constricted than before (eg., the model is implicitly guided\n",
    "to generate the digit 1 over any other digit).\n",
    "\n",
    "But, first, we begin with a few simple illustrations for the 1D and 2D heat equations and how it changes an input signal over time. Then, we'll see how observation noise on top of this deterministic heat equation makes inversion of the heat equation a feasible problem (Algorithm 1 of the paper).\n",
    "Finally, we'll end with some sample generation results for the MNIST and CIFAR10 datasets. \n",
    "\n",
    "Optionally, we can also train the model from scratch and observe the training process. Here, we have provided a simple training loop adapted from the main repository with corresponding training configurations in configs/mnist_cond.yaml. \n",
    "But, we provide the pre-trained weights for both CIFAR10 and MNIST, so you can skip the training process and directly observe the generation results.\n",
    "\n",
    "You can download weights for the class-conditoned models for both datasets [here](https://nextcloud.mpi-klsb.mpg.de/index.php/s/yAK9Z9kfn8T8fZy).\n",
    "\n",
    "Place them inside ```runs/{dataset}/conditional/checkpoints-meta/``` where ```dataset={mnist, cifar10}```.\n",
    "\n",
    "### Table of Contents\n",
    "- [Illustration of 1D Heat Equation](#illustration-of-1d-heat-equation)\n",
    "- [2D Heat Equation on Images](#2d-heat-equation-on-images)\n",
    "- [Train a class-conditional model on MNIST](#train-a-class-conditional-model-on-mnist)\n",
    "- [Implementation of the Sampling Algorithm](#implementation-of-the-sampling-algorithm)\n",
    "- [Sampling using a Trained Checkpoint](#sampling-using-a-trained-checkpoint)\n",
    "- [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as pjoin\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML, Image\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from einops import repeat, rearrange\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from scripts import utils\n",
    "\n",
    "config_mnist = OmegaConf.load(\"configs/mnist_cond.yaml\")\n",
    "config_cifar = OmegaConf.load(\"configs/cifar10_cond.yaml\")\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# For reproducibility\n",
    "utils.safe_state(config_mnist.seed, device)\n",
    "\n",
    "blur_sigma_max = config_mnist.model.blur_sigma_max\n",
    "blur_sigma_min = config_mnist.model.blur_sigma_min\n",
    "blur_schedule = np.exp(np.linspace(np.log(blur_sigma_min), np.log(blur_sigma_max), config_mnist.model.K))\n",
    "blur_schedule_cifar = np.exp(np.linspace(np.log(blur_sigma_min), np.log(blur_sigma_max), config_cifar.model.K))\n",
    "blur_schedule = np.array([0] + list(blur_schedule))  # Add the k=0 timestep\n",
    "blur_schedule_cifar = np.array([0] + list(blur_schedule_cifar))  # Add the k=0 timestep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Illustration of 1D heat equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial T}{\\partial t} = \\alpha \\left( \\frac{\\partial^2 T}{\\partial x^2} \\right)\n",
    "$$\n",
    "\n",
    "where $T$ is the temperature, $t$ is time, $x$ is the position, and $\\alpha$ is the thermal diffusivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "T(x,t) = \\sum_{n=0}^{\\infty} B_n \\cos \\left( \\frac{n \\pi x}{L} \\right) \\exp \\left( -\\alpha \\left( \\frac{n \\pi}{L} \\right)^2 t \\right)\n",
    "$$\n",
    "\n",
    "where $B_n$ are the Fourier coefficients and $L$ is the length of the rod. In the matrix exponential form, the solution can be written as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "T(\\mathbf{x}, t) = \\exp(\\mathbf{V} \\Lambda \\mathbf{V}^T t) T_0\n",
    "$$\n",
    "\n",
    "where $\\mathbf{V}$ is the matrix of eigenvectors of the laplacian operator, $\\Lambda$ is the diagonal matrix of eigenvalues of the laplacian operator, and $T_0$ is the initial temperature distribution. The above equation can be further simplified to:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "T(\\mathbf{x}, t) &= \\mathbf{V} \\exp(\\Lambda t) \\mathbf{V}^T T_0 \\\\\n",
    "\\mathbf{V}^T T(\\mathbf{x}, t) &= \\mathbf{V}^T \\mathbf{V} \\exp(\\Lambda t) \\mathbf{V}^T T_0 \\\\\n",
    "\\tilde{T}(\\mathbf{x}, t) &= \\exp(\\Lambda t) \\tilde{T}_0 \\\\\n",
    "T(\\mathbf{x}, t) &= \\mathbf{V} \\tilde{T}(\\mathbf{x}, t)\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining intial temperature profile of a rod of length L - a bi-modal or tri-modal distribution\n",
    "\n",
    "def gaussian(x, mean, std, amplitude=1):\n",
    "    return amplitude * torch.exp(-((x - mean) ** 2) / (2 * std ** 2))\n",
    "\n",
    "# Length of the rod\n",
    "L = 100\n",
    "x = torch.linspace(0, L, steps=L).to(device)\n",
    "\n",
    "# Bi-modal temperature distribution\n",
    "# Two Gaussians with means slightly off the center\n",
    "mean1 = L / 2 - L / 10\n",
    "mean2 = L / 2 + L / 10\n",
    "std = L / 20  # Standard deviation\n",
    "bi_modal_temp = gaussian(x, mean1, std) + gaussian(x, mean2, std)\n",
    "\n",
    "# Tri-modal temperature distribution with more spacing\n",
    "# Two Gaussians symmetrically around the center and one at the center\n",
    "mean1_tri = L / 2 - L / 6  # First peak moved further left\n",
    "mean2_tri = L / 2 + L / 6  # Second peak moved further right\n",
    "mean3 = L / 2  # Center peak\n",
    "std_tri = L / 20  # Standard deviation\n",
    "tri_modal_temp_spaced = gaussian(x, mean1_tri, std_tri) + gaussian(x, mean2_tri, std_tri) + gaussian(x, mean3, std_tri)\n",
    "\n",
    "# We deliberately set the edge values to be non-zero to show how the Neumann boundary condition sets in after t > 0\n",
    "bi_modal_temp[0] = 0.2\n",
    "bi_modal_temp[-1] = 0.9\n",
    "\n",
    "tri_modal_temp_spaced[0] = 0.4\n",
    "tri_modal_temp_spaced[-1] = 0.8\n",
    "\n",
    "# Plotting the temperature distributions\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Bi-modal temperature profile\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x.cpu().numpy(), bi_modal_temp.cpu().numpy())\n",
    "plt.title(\"Bi-modal Temperature Profile\")\n",
    "plt.xlabel(\"Position along the rod\")\n",
    "plt.ylabel(\"Temperature\")\n",
    "\n",
    "# Updated Tri-modal temperature profile\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x.cpu().numpy(), tri_modal_temp_spaced.cpu().numpy())\n",
    "plt.title(\"Updated Tri-modal Temperature Profile\")\n",
    "plt.xlabel(\"Position along the rod\")\n",
    "plt.ylabel(\"Temperature\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.torch_dct import DCTBlur1D, DCTBlur2D\n",
    "from scripts import datasets, losses\n",
    "\n",
    "heat_forward_module_1D = DCTBlur1D(blur_schedule, L, device)\n",
    "heat_forward_module_2D_mnist = DCTBlur2D(blur_schedule, config_mnist.data.image_size, device)\n",
    "heat_forward_module_2D_cifar = DCTBlur2D(blur_schedule_cifar, config_cifar.data.image_size, device)\n",
    "fwd_steps = torch.linspace(1, config_mnist.model.K, config_mnist.model.K, dtype=torch.long, device=device)\n",
    "fwd_steps_cifar = torch.linspace(1, config_cifar.model.K, config_cifar.model.K, dtype=torch.long, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will define some animation utility functions to visualize the heat equation (1D or 2D) changes an initial data distribution over time. For this, we'll observe the temperature evolution of a 1D rod over time which was heated at the center at time $t=0$.\n",
    "And when applied to a 2D images, we'll observe the progressive blurring of the image as the 2D heat equation gradually \"melts\" it. Note that, the forward pass of the heat equation is a deterministic process, and not a stochastic Markov noising process as seen in denoising\n",
    "diffusion models. As we saw above, the heat equation is solved by taking the input first to the Fourier domain, and then applying a matrix exponential of the eigenvalues of the Laplacian operator, and then transforming it back to the spatial domain using inverse DCT.\n",
    "\n",
    "The ```DCTBlur1D``` and ```DCTBlur2D``` classes defined in ```models/torch_dct.py``` implement this functionality for 1D and 2D inputs respectively. We can \"deterministically\" infer the blurred output at a given time $t$ by calling the ```forward``` method of these classes using the \n",
    "initial input and the time $t$ as input arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animate_rod_temperature(x, temp_profile):\n",
    "    fig, ax = plt.subplots()\n",
    "    # Plot the static background data\n",
    "    ax.plot(x.cpu().numpy(), temp_profile[0].cpu().numpy(), label='Temperature Profile at t=0')\n",
    "    # Setting the title and labels\n",
    "    ax.set_title('Temperature Profile at different time steps')\n",
    "    ax.set_xlabel('Position along the rod')\n",
    "    ax.set_ylabel('Temperature')\n",
    "\n",
    "    # Initialize the line for the animated part of the plot\n",
    "    line, = ax.plot([], [], lw=2, label='Temperature at t=0')  # Initial empty line\n",
    "    ax.set_xlim(0, L)  # Adjust x-axis limits based on your data\n",
    "    ax.set_ylim(0, 1)  # Adjust y-axis limits based on your data\n",
    "    ax.legend()\n",
    "\n",
    "    def init():\n",
    "        \"\"\"Initialize the background of the animation.\"\"\"\n",
    "        line.set_data([], [])\n",
    "        return line,\n",
    "\n",
    "    def animate(i):\n",
    "        \"\"\"Update the plot for each frame.\"\"\"\n",
    "        y = temp_profile[i].cpu().numpy()\n",
    "        line.set_data(x.cpu().numpy(), y)\n",
    "        line.set_label(f'Temperature at t={i}')  # Update the line label with the current frame\n",
    "        ax.legend()  # Update the legend\n",
    "        return line,\n",
    "\n",
    "    # Create animation\n",
    "    anim = FuncAnimation(fig, animate, init_func=init, frames=temp_profile.shape[0], interval=100, blit=True)\n",
    "\n",
    "    return HTML(anim.to_html5_video())\n",
    "\n",
    "\n",
    "def animate_image_blurring(blurred_images, cmap=None):\n",
    "    fig, ax = plt.subplots()\n",
    "    num_channels = blurred_images.shape[1]\n",
    "\n",
    "    # Use 'imshow' to display the first image; set the colormap to 'gray' for grayscale\n",
    "    im = ax.imshow(rearrange(blurred_images[0], 'c h w -> h w c').cpu().numpy(), cmap=cmap, vmin=0, vmax=1)\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Adding dynamic text annotation for timestep\n",
    "    # Position the text at the top-left corner of the axes\n",
    "    time_text = ax.text(0.02, 0.95, '', transform=ax.transAxes, color=\"yellow\", fontsize=12, bbox=dict(facecolor='black', alpha=0.5))\n",
    "\n",
    "    def init():\n",
    "        \"\"\"Initialize the animation with an empty frame.\"\"\"\n",
    "        im.set_data(np.zeros((blurred_images.shape[-2], blurred_images.shape[-1], num_channels)))\n",
    "        time_text.set_text('')  # Initialize the text\n",
    "        return im, time_text\n",
    "\n",
    "\n",
    "    def animate(i):\n",
    "        \"\"\"Update the image for each frame.\"\"\"\n",
    "        im.set_data(rearrange(blurred_images[i], 'c h w -> h w c').cpu().numpy())\n",
    "        time_text.set_text(f'Image at t={i}')  # Update the text with the current timestep\n",
    "        return im, time_text\n",
    "\n",
    "    # Create the animation\n",
    "    anim = FuncAnimation(fig, animate, init_func=init, frames=blurred_images.shape[0], interval=100, blit=True)\n",
    "\n",
    "    # Alternatively, to save the animation to a file\n",
    "    # anim.save('grayscale_animation.mp4', fps=20, extra_args=['-vcodec', 'libx264'])\n",
    "\n",
    "    # To display the animation in a Jupyter notebook\n",
    "    return HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_across_timesteps = heat_forward_module_1D(repeat(bi_modal_temp, 'd -> N d', N=config_mnist.model.K), fwd_steps)\n",
    "animate_rod_temperature(x, temp_across_timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_across_timesteps = heat_forward_module_1D(repeat(tri_modal_temp_spaced, 'd -> N d', N=config_mnist.model.K), fwd_steps)\n",
    "animate_rod_temperature(x, temp_across_timesteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice in the animations above, that the derivatives at the edges of the rod gradually go towards zero because of the homogeneous Neumann boundary conditions, and the temperature distribution becomes more and more uniform (diffused) over time. This is because the heat equation is a diffusion equation, and it diffuses the heat from the center to the edges of the rod. This is also the reason why the heat equation is used in image processing for blurring images as we'll see in the next set of animations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D Heat Equation on Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, testloader = datasets.get_dataset(config_mnist, uniform_dequantization=config_mnist.data.uniform_dequantization, eval_batch_size=1)\n",
    "sample_img_mnist = next(iter(testloader))[0].to(device)\n",
    "sample_img_mnist = repeat(sample_img_mnist, 'b c h w -> (b K) c h w', K=config_mnist.model.K)\n",
    "plt.imshow(sample_img_mnist[0, 0].cpu().numpy(), cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, testloader = datasets.get_dataset(config_cifar, uniform_dequantization=config_cifar.data.uniform_dequantization, eval_batch_size=1)\n",
    "sample_img_cifar = next(iter(testloader))[0].to(device)\n",
    "sample_img_cifar = repeat(sample_img_cifar, 'b c h w -> (b K) c h w', K=config_cifar.model.K)\n",
    "plt.imshow(np.transpose(sample_img_cifar[0].cpu().numpy(), (1, 2, 0)))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred_image_across_timesteps = heat_forward_module_2D_mnist(sample_img_mnist, fwd_steps)\n",
    "animate_image_blurring(blurred_image_across_timesteps, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final image at t=100 is a uniform gray image, which is the steady state solution of the heat equation. The average gray value of the final image is the same as the initial image.\n",
    "The evolution above follows the 2D heat equation:\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial u}{\\partial t} = \\alpha \\left( \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial x^2} \\right) \n",
    "$$\n",
    "\n",
    "whose general solution is given by:\n",
    "\n",
    "$$\n",
    "u(x, y, t) = \\sum_{n=0}^{\\infty} \\sum_{m=0}^{\\infty} B_{n,m} \\cos \\left( \\frac{n \\pi x}{L} \\right) \\cos \\left( \\frac{m \\pi y}{L} \\right) \\exp \\left( -\\alpha \\left( \\frac{n^2 + m^2}{L^2} \\right) t \\right)\n",
    "$$\n",
    "\n",
    "The Fourier domain solution is the same as the 1D case, only the dimension of the matrices are different as the Laplacian operator is now 2D instead of 1D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we see the same 2D heat equation applied to a CIFAR10 image. Following the settings of the paper, we run the blurring process for K=200 timesteps until we end up with a flat RGB image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred_image_across_timesteps = heat_forward_module_2D_cifar(sample_img_cifar, fwd_steps_cifar)\n",
    "animate_image_blurring(blurred_image_across_timesteps, cmap=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a class-conditional model on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ema import ExponentialMovingAverage\n",
    "\n",
    "workdir = \"runs/mnist/conditional_1\" # directory for saving checkpoints and evaluation outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for saving intermediate samples\n",
    "sample_dir = pjoin(workdir, \"samples\")\n",
    "Path(sample_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# create wandb project\n",
    "run = wandb.init(project=\"ihdm-talktorial\", entity=\"mvp18\", name=\"mnist_class_cond\", dir=workdir)\n",
    "run.name = run.name + f'-{run.id}'\n",
    "assert run is wandb.run\n",
    "\n",
    "model = utils.create_model(config_mnist, device)\n",
    "optimizer = utils.get_optimizer(config_mnist, model.parameters())\n",
    "\n",
    "ema = ExponentialMovingAverage(model.parameters(), decay=config_mnist.model.ema_rate)\n",
    "state = dict(optimizer=optimizer, model=model, step=0, ema=ema)\n",
    "model_evaluation_fn = utils.get_model_fn(model, train=False)\n",
    "\n",
    "# Create checkpoints directory\n",
    "checkpoint_dir = pjoin(workdir, \"checkpoints\")\n",
    "# Intermediate checkpoints to resume training\n",
    "checkpoint_meta_dir = pjoin(workdir, \"checkpoints-meta\", \"checkpoint.pth\")\n",
    "Path(checkpoint_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(os.path.dirname(checkpoint_meta_dir)).mkdir(parents=True, exist_ok=True)\n",
    "# Resume training when intermediate checkpoints are detected\n",
    "state = utils.restore_checkpoint(checkpoint_meta_dir, state, device)\n",
    "initial_step = int(state['step'])\n",
    "\n",
    "# Build data iterators\n",
    "trainloader, testloader = datasets.get_dataset(config_mnist, uniform_dequantization=config_mnist.data.uniform_dequantization)\n",
    "train_iter = iter(trainloader)\n",
    "eval_iter = iter(testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of the training algorithm\n",
    "\n",
    "<img src=\"media/algo1.png\" alt=\"Training Algorithm\" title=\"Training Algorithm\" width=\"700\" height=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inverse_heat_loss_fn(config, train, heat_forward_module):\n",
    "\n",
    "    sigma = config.model.sigma\n",
    "    label_sampling_fn = losses.get_label_sampling_function(config.model.K)\n",
    "\n",
    "    def loss_fn(model, x, y):\n",
    "        model_fn = utils.get_model_fn(model, train=train)  # get train/eval model\n",
    "        fwd_steps = label_sampling_fn(x.shape[0], x.device)\n",
    "        blurred_batch = heat_forward_module(x, fwd_steps).float()\n",
    "        less_blurred_batch = heat_forward_module(x, fwd_steps-1).float()\n",
    "        noise = torch.randn_like(blurred_batch) * sigma\n",
    "        perturbed_data = noise + blurred_batch\n",
    "        diff = model_fn(perturbed_data, fwd_steps, y)\n",
    "        prediction = perturbed_data + diff\n",
    "        losses = (less_blurred_batch - prediction)**2\n",
    "        losses = torch.sum(losses.reshape(losses.shape[0], -1), dim=-1)\n",
    "        loss = torch.mean(losses)\n",
    "        return loss, losses, fwd_steps\n",
    "\n",
    "    return loss_fn\n",
    "\n",
    "# Get the forward process definition\n",
    "loss_fn_train = get_inverse_heat_loss_fn(config_mnist, train=True, heat_forward_module=heat_forward_module_2D_mnist)\n",
    "loss_fn_eval = get_inverse_heat_loss_fn(config_mnist, train=False, heat_forward_module=heat_forward_module_2D_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build one-step training and evaluation functions\n",
    "optimize_fn = losses.optimization_manager(config_mnist)\n",
    "\n",
    "# Get the loss function\n",
    "train_step_fn = losses.get_step_fn(train=True, config=config_mnist, loss_fn=loss_fn_train, optimize_fn=optimize_fn)\n",
    "eval_step_fn = losses.get_step_fn(train=False, config=config_mnist, loss_fn=loss_fn_eval, optimize_fn=optimize_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Implementation of the Sampling Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"media/algo2.png\" alt=\"Sampling Algorithm\" title=\"Sampling Algorithm\" width=\"700\" height=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_initial_sample(config, forward_heat_module, device, batch_size=None):\n",
    "    \"\"\"Take a draw from the prior p(u_K)\"\"\"\n",
    "    trainloader, _ = datasets.get_dataset(config, uniform_dequantization=config.data.uniform_dequantization, train_batch_size=batch_size)\n",
    "\n",
    "    initial_sample = next(iter(trainloader))\n",
    "    initial_images = initial_sample[0].to(device)\n",
    "    original_class = initial_sample[1].to(device) if config.data.num_classes is not None else None\n",
    "    initial_sample = forward_heat_module(initial_images, config.model.K * torch.ones(initial_images.shape[0], dtype=torch.long).to(device))\n",
    "    return initial_sample, original_class\n",
    "\n",
    "\n",
    "def get_sampling_fn_inverse_heat(config, initial_sample, initial_class, intermediate_sample_indices, delta, device, share_noise=False):\n",
    "    \"\"\" Returns our inverse heat process sampling function. \n",
    "    Arguments: \n",
    "    initial_sample: Pytorch Tensor with the initial draw from the prior p(u_K)\n",
    "    intermediate_sample_indices: list of indices to save (e.g., [0,1,2,3...] or [0,2,4,...])\n",
    "    delta: Standard deviation of the sampling noise\n",
    "    share_noise: Whether to use the same noises for all elements in the batch\n",
    "    \"\"\"\n",
    "    K = config.model.K\n",
    "\n",
    "    def sampler(model):\n",
    "\n",
    "        if share_noise:\n",
    "            noises = [torch.randn_like(initial_sample[0], dtype=torch.float)[None] for i in range(K)]\n",
    "        \n",
    "        intermediate_samples_out = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            u = initial_sample.to(device).float()\n",
    "            if intermediate_sample_indices != None and K in intermediate_sample_indices:\n",
    "                intermediate_samples_out.append((u, u))\n",
    "            for i in range(K, 0, -1):\n",
    "                vec_fwd_steps = torch.ones(initial_sample.shape[0], device=device, dtype=torch.long) * i\n",
    "                # Predict less blurry mean\n",
    "                u_mean = model(u, vec_fwd_steps, initial_class) + u\n",
    "                # Sampling step\n",
    "                if share_noise:\n",
    "                    noise = noises[i-1]\n",
    "                else:\n",
    "                    noise = torch.randn_like(u)\n",
    "                \n",
    "                u = u_mean + noise*delta\n",
    "                # Save trajectory\n",
    "                if intermediate_sample_indices != None and i-1 in intermediate_sample_indices:\n",
    "                    intermediate_samples_out.append((u, u_mean))\n",
    "\n",
    "            return u_mean, [u for (u, u_mean) in intermediate_samples_out]\n",
    "    \n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = config_mnist.model.sigma * 1.25\n",
    "# Building sampling functions\n",
    "initial_sample, initial_class = get_initial_sample(config_mnist, heat_forward_module_2D_mnist, device)\n",
    "sampling_fn = get_sampling_fn_inverse_heat(config_mnist, initial_sample, initial_class, intermediate_sample_indices=list(range(config_mnist.model.K+1)), delta=delta, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_steps = config_mnist.training.n_iters\n",
    "\n",
    "for step in range(initial_step, num_train_steps + 1):\n",
    "        # Train step\n",
    "        try:\n",
    "            batch = next(train_iter)\n",
    "        except StopIteration:  # Start new epoch if run out of data\n",
    "            train_iter = iter(trainloader)\n",
    "            batch = next(train_iter)\n",
    "\n",
    "        x = batch[0].to(device).float()\n",
    "        y = batch[1].to(device) if config_mnist.data.num_classes is not None else None\n",
    "        loss, losses_batch, fwd_steps_batch = train_step_fn(state, x, y)\n",
    "\n",
    "        wandb.log({\"training_loss\": loss.item()}, step)\n",
    "\n",
    "        # Save a temporary checkpoint to resume training if training is stopped\n",
    "        if step != 0 and step % config_mnist.training.snapshot_freq_for_preemption == 0:\n",
    "            (\"Saving temporary checkpoint\")\n",
    "            utils.save_checkpoint(checkpoint_meta_dir, state)\n",
    "\n",
    "        # Report the loss on an evaluation dataset periodically\n",
    "        if step % config_mnist.training.eval_freq == 0:\n",
    "            print(\"Starting evaluation\")\n",
    "            # Use 25 batches for test-set evaluation, arbitrary choice\n",
    "            N_evals = 25\n",
    "            for i in range(N_evals):\n",
    "                try:\n",
    "                    eval_batch = next(eval_iter)\n",
    "                except StopIteration:  # Start new epoch\n",
    "                    eval_iter = iter(testloader)\n",
    "                    eval_batch = next(eval_iter)\n",
    "\n",
    "                x_eval = eval_batch[0].to(device).float()\n",
    "                y_eval = eval_batch[1].to(device) if config_mnist.data.num_classes is not None else None\n",
    "                eval_loss, losses_batch, fwd_steps_batch = eval_step_fn(state, x_eval, y_eval)\n",
    "                eval_loss = eval_loss.detach()\n",
    "                wandb.log({\"eval_loss\": eval_loss.item()}, step)\n",
    "            print(f\"step: {step}, eval_loss: {eval_loss.item()}\")\n",
    "\n",
    "        # Save a checkpoint periodically\n",
    "        if step != 0 and step % config_mnist.training.snapshot_freq == 0 or step == num_train_steps:\n",
    "            print(\"Saving a checkpoint\")\n",
    "            # Save the checkpoint.\n",
    "            save_step = step // config_mnist.training.snapshot_freq\n",
    "            utils.save_checkpoint(pjoin(checkpoint_dir, 'checkpoint_{}.pth'.format(save_step)), state)\n",
    "\n",
    "        # Generate samples periodically\n",
    "        if step != 0 and step % config_mnist.training.sampling_freq == 0 or step == num_train_steps:\n",
    "            print(\"Sampling...\")\n",
    "            ema.store(model.parameters())\n",
    "            ema.copy_to(model.parameters())\n",
    "            sample, intermediate_samples = sampling_fn(model_evaluation_fn)\n",
    "            ema.restore(model.parameters())\n",
    "            this_sample_dir = pjoin(sample_dir, \"iter_{}\".format(step))\n",
    "            Path(this_sample_dir).mkdir(parents=True, exist_ok=True)\n",
    "            # utils.save_tensor(this_sample_dir, sample, \"final.np\")\n",
    "            utils.save_png(this_sample_dir, sample, \"final.png\")\n",
    "            if initial_sample != None: utils.save_png(this_sample_dir, initial_sample, \"init.png\")\n",
    "            # utils.save_gif(this_sample_dir, intermediate_samples)\n",
    "            utils.save_video(this_sample_dir, intermediate_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling using a Trained Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(config, heat_forward_module, batch_size, same_init_u=False, same_init_class=False, share_noise=False, workdir=None):\n",
    "\n",
    "    intermediate_sample_indices = list(range(config.model.K+1))\n",
    "    delta = config.model.sigma * 1.25 # The standard deviation of noise to add at each step with predicted reverse blur\n",
    "\n",
    "    # Directory name for saving results\n",
    "    sample_dir = pjoin(workdir, \"additional_samples\")\n",
    "    this_sample_dir = pjoin(sample_dir, \"checkpoint_0\")\n",
    "    this_sample_dir = pjoin(this_sample_dir, \"delta_{}\".format(delta))\n",
    "\n",
    "    checkpoint_dir = pjoin(workdir, \"checkpoints-meta\")\n",
    "    print(checkpoint_dir)\n",
    "    model = utils.load_model_from_checkpoint_dir(config, checkpoint_dir, device)\n",
    "    model_fn = utils.get_model_fn(model, train=False)\n",
    "    print(f\"Loaded model from {checkpoint_dir} running on {device}\")\n",
    "    \n",
    "    initial_sample, initial_class = get_initial_sample(config, heat_forward_module, device, batch_size=batch_size)\n",
    "    initial_sample = initial_sample[:batch_size]\n",
    "\n",
    "    if same_init_u:\n",
    "        initial_sample = torch.cat(batch_size * [initial_sample[0][None]], 0)\n",
    "        this_sample_dir += \"_same_init\"\n",
    "    if same_init_class:\n",
    "        initial_class = torch.cat(batch_size * [initial_class[0][None]], 0)\n",
    "        this_sample_dir += \"_same_class\"\n",
    "    if share_noise:\n",
    "        this_sample_dir += \"_share_noise\"\n",
    "\n",
    "    Path(this_sample_dir).mkdir(parents=True, exist_ok=True)\n",
    "    sampling_fn = get_sampling_fn_inverse_heat(config, initial_sample, initial_class, intermediate_sample_indices, delta, device, share_noise=True)\n",
    "    sample, intermediate_samples = sampling_fn(model_fn)\n",
    "\n",
    "    utils.save_png(this_sample_dir, sample, \"final.png\")\n",
    "    utils.save_png(this_sample_dir, initial_sample, \"init.png\")\n",
    "    utils.save_video(this_sample_dir, intermediate_samples)\n",
    "\n",
    "    if config.data.dataset == \"CIFAR10\":\n",
    "        cifar_classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "        initial_class = [cifar_classes[i] for i in initial_class.cpu().numpy()]\n",
    "    print(f\"Sample classes: {initial_class}\")\n",
    "    print(f\"Output sample saved at {this_sample_dir}\")\n",
    "    return Image(pjoin(this_sample_dir, \"final.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workdir_mnist = \"runs/mnist/conditional\"\n",
    "workdir_cifar = \"runs/cifar10/conditional\"\n",
    "sample_batch_size = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### No sharing across samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_init_u = False\n",
    "same_init_class = False\n",
    "share_noise = False\n",
    "\n",
    "sample(config_mnist, heat_forward_module_2D_mnist, sample_batch_size, same_init_u, same_init_class, share_noise, workdir_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_init_u = False\n",
    "same_init_class = False\n",
    "share_noise = False\n",
    "\n",
    "sample(config_cifar, heat_forward_module_2D_cifar, sample_batch_size, same_init_u, same_init_class, share_noise, workdir_cifar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "\n",
    "MNIST results are accurate and follow the class signal accurately. CIFAR10 results look to be accurate for most classes, but the \"airplane\" class generations don't look that plausible. For example, one of the airplane samples look more like a flying bat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Same prior initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_init_u = True\n",
    "same_init_class = False\n",
    "share_noise = False\n",
    "\n",
    "sample(config_mnist, heat_forward_module_2D_mnist, sample_batch_size, same_init_u, same_init_class, share_noise, workdir_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_init_u = True\n",
    "same_init_class = False\n",
    "share_noise = False\n",
    "\n",
    "sample(config_cifar, heat_forward_module_2D_cifar, sample_batch_size, same_init_u, same_init_class, share_noise, workdir_cifar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "\n",
    "It's easier for the MNIST model to follow the class signal even under the same prior initialization as most digits would most likely \"melt down\" to similar average gray values. CIFAR10 results are suprisingly quite accurate despite every image starting from the average gray value of a truck sample.\n",
    "Only the cat samples look a bit off, as they resemble the deer class more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Same class conditioning signal for all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_init_u = False\n",
    "same_init_class = True\n",
    "share_noise = False\n",
    "\n",
    "sample(config_mnist, heat_forward_module_2D_mnist, sample_batch_size, same_init_u, same_init_class, share_noise, workdir_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_init_u = False\n",
    "same_init_class = True\n",
    "share_noise = False\n",
    "\n",
    "sample(config_cifar, heat_forward_module_2D_cifar, sample_batch_size, same_init_u, same_init_class, share_noise, workdir_cifar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "\n",
    "This setting is again easier for the MNIST model to follow the class signal due to reasons mentioned above. But it still does quite well at creating diverse looking \"2\"'s. For CIFAR10, the model does mostly well at generating ships from different gray values, except maybe 1 or 2 samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Same prior and same class signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_init_u = True\n",
    "same_init_class = True\n",
    "share_noise = False\n",
    "\n",
    "sample(config_mnist, heat_forward_module_2D_mnist, sample_batch_size, same_init_u, same_init_class, share_noise, workdir_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_init_u = True\n",
    "same_init_class = True\n",
    "share_noise = False\n",
    "\n",
    "sample(config_cifar, heat_forward_module_2D_cifar, sample_batch_size, same_init_u, same_init_class, share_noise, workdir_cifar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "\n",
    "This is the most limited setting for the model, and it's quite hard for even the MNIST model to generate diverse samples. But because of 2 simultaneous constraints, the CIFAR10 model seems to do the best here at creating a sample well representative of the class signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sharing noise between consecutive deblurring timesteps in Algorithm 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_init_u = False\n",
    "same_init_class = False\n",
    "share_noise = True\n",
    "\n",
    "sample(config_mnist, heat_forward_module_2D_mnist, sample_batch_size, same_init_u, same_init_class, share_noise, workdir_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_init_u = False\n",
    "same_init_class = False\n",
    "share_noise = True\n",
    "\n",
    "sample(config_cifar, heat_forward_module_2D_cifar, sample_batch_size, same_init_u, same_init_class, share_noise, workdir_cifar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "\n",
    "Sharing noise between consecutve timesteps seems to help the model in generating sharper, but not necessarily more accurate samples. The CIFAR10 model seems to be better at distinguishing these properties as the MNIST generation task is quite simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Same prior initialization and sharing noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_init_u = True\n",
    "same_init_class = False\n",
    "share_noise = True\n",
    "\n",
    "sample(config_mnist, heat_forward_module_2D_mnist, sample_batch_size, same_init_u, same_init_class, share_noise, workdir_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_init_u = True\n",
    "same_init_class = False\n",
    "share_noise = True\n",
    "\n",
    "sample(config_cifar, heat_forward_module_2D_cifar, sample_batch_size, same_init_u, same_init_class, share_noise, workdir_cifar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observation:\n",
    "\n",
    "The MNIST model is able to generate sharp representative class samples because of noise sharing even with the constraint of prior initialization. However, this additional constraint cripples the CIFAR10 model as it struggles to generate accurate samples\n",
    "from other classes except for the ship class whose prior is shared across all samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "\n",
    "In this notebook, we have investigated class-conditonal generation of the Inverse Heat Dissipation Model (IHDM) for the MNIST and CIFAR10 datasets. The main takeaway seems to be an unconditional model (as observed in the paper) for RGB images would be skewed towards generating a only a specific set of classes without any class conditioning signal, but just based on the prior distribution. However, with a class input, the model will try to generate an instance of the target class with an average gray value that it may not have encountered during training. However, the generation may not look always plausible as certain classes are only correlated with a certain range of average gray levels in the training data. This is a limitation of the model, and it would be interesting to see how the model can be extended to generate more plausible samples with a class conditioning signal.\n",
    "\n",
    "Next, we'll be looking to develop a latent diffusion version of IHDM, and see how blurring/deblurring can be interpreted as a diffusion process in the latent space."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
